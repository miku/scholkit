# Misc observations

To save disk space, we recompress the openalex-works with zstd `-19` - file
shrinks from 316GB to 218GB (0.68 of original), but the compression process
takes 18 hours of full 32 core CPU load.

```
$ time zstdcat -T0 openalex-works-2024-04-17.ndj.zst | pv | zstd -c19 -T0 > openalex-works-2024-04-17.ndj.zst.19
2.28TiB 18:01:08 [36.9MiB/s] [
real    1081m31.126s
user    33369m49.024s
sys     27m51.071s
```

Total file size is 2.28TB uncompressed; we can save up to 90% of disk space; or
8TB could hold maybe something like 80TB, 16TB something like 160TB, etc.

Iterating over 250M openalex records takes about 36min, or 116K records/s.

```
$ zstdcat -T0 openalex-works-2024-04-17.ndj.zst | pv -l > /dev/null
250M 0:35:57 [ 115k/s] [
```

## Reruns

```
$ time zstdcat -T0 openalex-works-2024-04-17.ndj.zst | \
    catshape -f openalex | \
    pv -l | \
    zstd -c -T0 > ~/code/miku/scholkit/data/input/openalex.ndj.zst

 250M 1:03:49 [65.3k/s] [

real    63m50.926s
user    527m14.321s
sys     42m32.610s
```
