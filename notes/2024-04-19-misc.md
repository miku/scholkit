# Misc observations

To save disk space, we recompress the openalex-works with zstd `-19` - file
shrinks from 316GB to 218GB (0.68 of original), but the compression process
takes 18 hours of full 32 core CPU load.

```
$ time zstdcat -T0 openalex-works-2024-04-17.ndj.zst | pv | zstd -c19 -T0 > openalex-works-2024-04-17.ndj.zst.19
2.28TiB 18:01:08 [36.9MiB/s] [
real    1081m31.126s
user    33369m49.024s
sys     27m51.071s
```

Total file size is 2.28TB uncompressed; we can save up to 90% of disk space; or
8TB could hold maybe something like 80TB, 16TB something like 160TB, etc.

Iterating over 250M openalex records takes about 36min, or 116K records/s.

```
$ zstdcat -T0 openalex-works-2024-04-17.ndj.zst | pv -l > /dev/null
250M 0:35:57 [ 115k/s] [
```

## Reruns

```
$ time zstdcat -T0 openalex-works-2024-04-17.ndj.zst | \
    catshape -f openalex | \
    pv -l | \
    zstd -c -T0 > ~/code/miku/scholkit/data/input/openalex.ndj.zst

 250M 1:03:49 [65.3k/s] [

real    63m50.926s
user    527m14.321s
sys     42m32.610s
```

new fatcat lost some million records (but where?):

```
$ zstdcat -T0 /var/data/tmp/fatcat.ndj.zst | pv -l | wc -l
812M 0:09:14 [1.46M/s] [                                                                                                                                                                                             <=>                     ]
812130550
```

it takes 10min to copy 100G from nvme to sata ssd:

```
$ time cp /var/data/tmp/fatcat.ndj.zst .

real    10m30.432s
user    0m0.106s
sys     1m20.571s
```

## cat files

```
$ time cat input/*zst | pv > /var/data/tmp/fatcat.ndj.zst

96.1GiB 0:04:13 [ 388MiB/s] [

real    4m14.192s
user    0m0.699s
sys     2m15.785s
```

