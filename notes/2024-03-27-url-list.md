# URL list

Extracting URL like substrings from 850M docs.

## Basic numbers

```
$ time zstdcat -T0 fatcat.ndj.zst | \
    pv -l | \
    parallel --pipe --block 10M -j 32 "grep -Eo 'https?://[^\" >)}]*'" | \
    zstd -c -T0 > fatcat-url-like.txt.zst

real    11m32.563s
user    57m25.116s
sys     31m33.041s
```

398565432 url like strings.

```
$ time zstdcat -T0 fatcat-url-like.txt.zst | \
    LC_ALL=C sort -S80% -u | \
    zstd -c -T0 > fatcat-url-like-uniq.txt.zst

real    1m30.361s
user    4m47.065s
sys     0m46.888s
```

Unique: 249,697,974

How many end with PDF? About 33M.

```
$ zstdcat -T0 fatcat-url-like-uniq.txt.zst | \
    grep -c 'pdf$'
33370429
```

## Samping from CDX

```
$ zstdcat -T0 fatcat-url-like-uniq.txt.zst | \
    LC_ALL=C grep 'pdf$' | \
    shuf -n 10000 > fatcat-url-like-sample-10000.txt

$ time cat fatcat-url-like-sample-10000.txt | pv -l | \
    cdxlookup -C > fatcat-url-like-sample-10000-lookup-count.txt
```

We find that about 20% of the "PDF" subsample does not have an archival copy yet.

```
$ jq -rc .count /magna/tmp/fatcat-url-like-sample-10000-count.txt|sort| uniq -c | sort -nr
   7932 1
   2068 0
```

We find 572 unique hostnames in the set, top hosts with missing archives:

```
$ jq -rc 'select(.count == 0) | .url' fatcat-url-like-sample-10000-count.txt  | \
    awk -F / '{print $3}' | sort | uniq -c | sort -nr | head -20
    116 www.scielo.br
    105 zenodo.org
     84 link.springer.com
     43 figshare.com
     40 www.degruyter.com
     39 hal.archives-ouvertes.fr
     39 academic.oup.com
     32 www.researchsquare.com
     30 www.jbc.org
     28 www.nature.com
     28 ieeexplore.ieee.org
     27 manuscript.elsevier.com
     24 www.jstage.jst.go.jp
     23 ir.uitm.edu.my
     22 acta.bibl.u-szeged.hu
     21 www.redalyc.org
     21 pure.eur.nl
     20 ri.conicet.gov.ar
     18 real.mtak.hu
     17 repository.unair.ac.id
```

